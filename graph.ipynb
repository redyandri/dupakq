{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ac7591a-877d-4f13-a9eb-d08a5b037912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tag import CRFTagger\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory \n",
    "from nltk.tokenize import RegexpTokenizer \n",
    "import nltk\n",
    "import re\n",
    "from neo4j import GraphDatabase\n",
    "from nltk.stem import PorterStemmer\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f49ecace-f430-491f-82f8-69132aa2846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\",None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6c4d13d-4dc9-4f84-aa4d-87b1b0b924b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6b6428b-15d5-4e1f-8057-0c22357d82dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5cd915e-081d-4ce4-8365-8c66ed0b5dc8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/dupak20221010.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8842/487518486.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_dupak_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/dupak20221010.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_dupak_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pusintek/miniconda3/envs/py38/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pusintek/miniconda3/envs/py38/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pusintek/miniconda3/envs/py38/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pusintek/miniconda3/envs/py38/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pusintek/miniconda3/envs/py38/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1218\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pusintek/miniconda3/envs/py38/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    790\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/dupak20221010.csv'"
     ]
    }
   ],
   "source": [
    "df_dupak_all=pd.read_csv(\"data/dupak20221010.csv\",sep=\";\")\n",
    "df_dupak_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6236b9ca-55a4-43a7-965d-d4dc658016f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger=CRFTagger()\n",
    "tagger.set_model_file(r\"model/all_indo_man_tag_corpus_model.crf.tagger\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d00c567d-bd13-47d1-bc27-852a0d75a302",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'[a-zA-Z]+')\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "df_id_stopword=pd.read_csv(\"data/stopwordbahasa.csv\",header=None)\n",
    "id_stopword=df_id_stopword[0].to_list()\n",
    "\n",
    "def tokenize_clean(text):\n",
    "    if(text):\n",
    "        tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word\n",
    "            in nltk.word_tokenize(sent)]\n",
    "        #clean token from numeric and other character like puntuation\n",
    "        filtered_tokens = []\n",
    "        for token in tokens:\n",
    "            txt=re.findall('[a-zA-Z]{3,}', token)\n",
    "            if txt:\n",
    "                filtered_tokens.append(txt[0])       \n",
    "        return filtered_tokens\n",
    "\n",
    "def remove_stopwords(tokenized_text):\n",
    "    if(tokenized_text):\n",
    "        cleaned_token = []\n",
    "        for token in tokenized_text:\n",
    "            if token not in id_stopword:\n",
    "                cleaned_token.append(token)\n",
    "\n",
    "        return cleaned_token\n",
    "\n",
    "def stem_text(tokenized_text):\n",
    "    if (tokenized_text):\n",
    "        stems = []\n",
    "        for token in tokenized_text:\n",
    "            stems.append(stemmer.stem(token))\n",
    "\n",
    "        return stems\n",
    "\n",
    "def remove_en_stopwords(text):\n",
    "    if text:\n",
    "        return [token for token in text if token not in en_stopwords]\n",
    "\n",
    "def stem_en_text(text):\n",
    "    if text:\n",
    "        return [en_stemmer.stem(word) for word in text]\n",
    "\n",
    "def revome_slash_n(text):\n",
    "    if text:\n",
    "        return [str(txt).replace(\"\\n\",\" \") for txt in text]\n",
    "\n",
    "def lower_text(text):\n",
    "    if text:\n",
    "        return [str(txt).lower() for txt in text]\n",
    "\n",
    "def make_sentence(arr):\n",
    "    if arr:\n",
    "        return \" \".join(arr)\n",
    "    \n",
    "def text_preprocessing_id(text):\n",
    "    if text:\n",
    "        prep01 = tokenize_clean(text)\n",
    "        prep02 = remove_stopwords(prep01)\n",
    "        prep03 = stem_text(prep02)\n",
    "#         prep04 = remove_en_stopwords(prep03)\n",
    "#         prep05 = stem_en_text(prep04)\n",
    "        prep06 = revome_slash_n(prep03)\n",
    "        prep07 = lower_text(prep06)\n",
    "        prep08 = make_sentence(prep07)\n",
    "        return prep08\n",
    "\n",
    "def text_preprocessing_en(text):\n",
    "    if text:\n",
    "        prep01 = tokenize_clean(text)\n",
    "#         prep02 = remove_stopwords(prep01)\n",
    "#         prep03 = stem_text(prep02)\n",
    "        prep04 = remove_en_stopwords(prep01)\n",
    "        prep05 = stem_en_text(prep04)\n",
    "        prep06 = revome_slash_n(prep05)\n",
    "        prep07 = lower_text(prep06)\n",
    "        prep08 = make_sentence(prep07)\n",
    "        return prep08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc1479c3-37b4-4383-8215-219912378f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'penuh minta layan teknologi informasi'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocessing_id(\"pemenuhan permintaan dan layanan teknologi informasi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0560cea-030b-41a4-8b80-bf6160872cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[('melakukan', 'VB'),\n",
       "   ('pemenuhan', 'NN'),\n",
       "   ('permintaan', 'NN'),\n",
       "   ('dan', 'CC'),\n",
       "   ('layanan', 'NN'),\n",
       "   ('teknologi', 'NN'),\n",
       "   ('informasi', 'NN')]],\n",
       " [[('penuh', 'JJ'),\n",
       "   ('minta', 'VB'),\n",
       "   ('layan', 'NN'),\n",
       "   ('teknologi', 'NN'),\n",
       "   ('informasi', 'NN')]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged0=tagger.tag_sents([\"melakukan pemenuhan permintaan dan layanan teknologi informasi\".split()])\n",
    "tagged1=tagger.tag_sents([text_preprocessing_id(\"melakukan pemenuhan permintaan dan layanan teknologi informasi\").split()])\n",
    "tagged0,tagged1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9bbd2121-37c3-4165-a1f8-bade6048a00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method CRFTagger.tag of <nltk.tag.crf.CRFTagger object at 0x7f32b44d7370>>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a43463e1-2416-4f3a-ab9e-49906e3b2ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VB', 'NN', 'NN', 'CC', 'NN', 'NN', 'NN']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pos for i,pos in tagged0[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab761d14-4c56-46ff-8391-be380cc3f2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neo4j in /home/pusintek/miniconda3/envs/py38/lib/python3.8/site-packages (4.4.6)\n",
      "Requirement already satisfied: pytz in /home/pusintek/miniconda3/envs/py38/lib/python3.8/site-packages (from neo4j) (2021.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a1ab338e-caa9-4fcd-9e3d-5d79841adcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neo4j_Connect:\n",
    "\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "    def print_greeting(self, message):\n",
    "        with self.driver.session() as session:\n",
    "            greeting = session.write_transaction(self._create_and_return_greeting, message)\n",
    "            print(greeting)\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_and_return_greeting(tx, message):\n",
    "        result = tx.run(\"CREATE (a:Greeting) \"\n",
    "                        \"SET a.message = $message \"\n",
    "                        \"RETURN a.message + ', from node ' + id(a)\", message=message)\n",
    "        return result.single()[0]\n",
    "    \n",
    "    def add_relation(self, node1,rel,node2,score,idx):\n",
    "        with self.driver.session() as session:\n",
    "            res = session.write_transaction(self._add_relation, node1,rel,node2,score,idx)\n",
    "            print(res)\n",
    "\n",
    "    @staticmethod\n",
    "    def _add_relation(tx, node1,rel,node2,score,idx):\n",
    "        result = tx.run(\"MERGE (p:NODE {label:$node1})\"\n",
    "                        \"MERGE (d:NODE {label:$node2})\"\n",
    "                        \"WITH p,d\"\n",
    "                        \" CALL apoc.create.relationship(p,$rel,{label:$rel,score:$score,idx:$idx},d)\"\n",
    "                        \"YIELD rel \"\n",
    "                        \"RETURN rel\",\n",
    "                       node1=node1,rel=rel,score=score,node2=node2,idx=idx)\n",
    "        \n",
    "        return result.single()[0]\n",
    "    \n",
    "    def query(self, m='',n=''):\n",
    "        m='kumpul informasi'\n",
    "        n='data instansi'\n",
    "        with self.driver.session() as session:\n",
    "            result = session.read_transaction(self._query, m,n)\n",
    "        return result\n",
    "#             print(res)\n",
    "\n",
    "    @staticmethod\n",
    "    def _query(tx, m,n):\n",
    "        result = tx.run(\"match p=(m)-[r]-(n) where m.label contains 'instalasi' or n.label contains 'sistem operasi' return m as noun1, r as relation,m as noun2\",\n",
    "                       m=m,n=n)\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "\n",
    "n4j = Neo4j_Connect(\"bolt://10.242.184.93:7687\", \"neo4j\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "230669c1-d10e-4f8e-9ddd-03327ab741c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bismillah, from node 214\n"
     ]
    }
   ],
   "source": [
    "n4j.print_greeting(\"bismillah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a56ad824-ab28-4ffd-86c5-0730c1551728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Relationship id=410 nodes=(<Node id=212 labels=frozenset() properties={}>, <Node id=213 labels=frozenset() properties={}>) type='menyusun' properties={'idx': 147, 'score': 0.5}>\n"
     ]
    }
   ],
   "source": [
    "n4j.add_relation(\"ahli pertama\",\"menyusun\",\"kajian teknis\",0.5,147)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69ef0771-1a25-498b-93be-476f32f57fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'menyiapkan peralatan video conference (vicon/streaming ), monitoring peralatan (audio,\\nvideo, dan perangkat jaringan), mengatur layout'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=0\n",
    "s=\"\"\n",
    "for i,row in df_dupak_all.iterrows():\n",
    "    l2=len(row.activity_last_part)\n",
    "    if  l2>l:\n",
    "        l=l2\n",
    "        s=row.activity_last_part\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb1f600c-3c6c-4626-9663-cc28398fff52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNP_0 NNP_1 VB_2 NN_3 NN_4 FW_5 FW_6 Z_7 FW_8 NN_9 FW_10 FW_11 CC_12 NN_13 NN_14 NN_15 VB_16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' FW_5 FW_6 Z_7 FW_8 ']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt='Ahli Muda menyiapkan peralatan video conference (vicon/streaming ), monitoring peralatan (audio,\\nvideo, dan perangkat jaringan), mengatur layout'\n",
    "tagged0=tagger.tag_sents([txt.split()])\n",
    "ori_pos=[pos[-1]+\"_\"+str(i) for i,pos in enumerate(tagged0[0])]\n",
    "s=\" \".join(ori_pos)\n",
    "print(s)\n",
    "re.findall(\"[NNP_\\d]{4,6}\\s[NNP_\\d]*\\s*[NNP_\\d]*\\s*[^NNP]+\\s[NNP_\\d]{4,6}\\s*[NNP_\\d]*\\s*[NNP_\\d]*\\s*\",s)\n",
    "arr=re.findall(\"[NNP_\\d]{4,6}\\s[NNP_\\d]*\\s*[NNP_\\d]*\\s*[NNP_\\d]*\\s*\",s)\n",
    "re.findall(\"(?<=NN_3 NN_4).*?(?=NN_9)\",s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "426257e3-9617-4ec6-ba5d-7304427ca29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['activities', 'activity_code', 'ak', 'batas_penilaian', 'jenjang',\n",
       "       'kegiatan', 'nomor_sub_unsur', 'nomor_unsur', 'sub_unsur', 'unsur',\n",
       "       'activity_cleansed', 'tfidf_vec', 'activity_enriched',\n",
       "       'activity_enriched_cleansed', 'tfidf_vec_enriched', 'actvity_code_only',\n",
       "       'activity_last_part', 'activity_code_only', 'evidents'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dupak_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3507f106-104e-4fe4-bfb5-45d77bd3ee31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    melakukan pemenuhan permintaan dan layanan teknologi informasi\n",
       "1            melakukan pengumpulan informasi mengenai data instansi\n",
       "Name: activity_last_part, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dupak_all.activity_last_part.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "854404e6-2734-4ea8-894c-f7568aea8e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147    Tata Kelola dan Tata Laksana Teknologi Informasi.Pengelolaan data (Data management).Melakukan perancangan data model\n",
       "Name: activities, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dupak_all[df_dupak_all.index==147][\"activities\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d6115d-b84d-42da-8bc5-2f9baa05068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_activity(txt):\n",
    "    return txt.split(\".\")[-1]\n",
    "\n",
    "def complete_sentence_with_subject(row):\n",
    "    arr=tagger.tag_sents([row.activity_last_part.split()])\n",
    "    s=row.activity_last_part\n",
    "    if arr[0][0][-1] not in [\"NN\",\"NNP\"]:\n",
    "        s=row.sub_unsur+\" - \"+row.activity_last_part\n",
    "        print(\"\\r{}---->{}\".format(row.activity_last_part,s),end='')\n",
    "    return s\n",
    "df_dupak_all.activity_last_part=df_dupak_all.activities.apply(get_last_activity)\n",
    "df_dupak_all.activity_last_part=df_dupak_all.apply(complete_sentence_with_subject,axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e84d9b3-440d-4be7-87f3-82e034bb3b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      None\n",
       "1      None\n",
       "2      None\n",
       "3      None\n",
       "4      None\n",
       "       ... \n",
       "331    None\n",
       "332    None\n",
       "333    None\n",
       "334    None\n",
       "335    None\n",
       "Length: 336, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def print_subject(row):\n",
    "    arr=tagger.tag_sents([row.activity_last_part.split()])\n",
    "    s=row.activity_last_part\n",
    "    if arr[0][0][-1] not in [\"NN\",\"NNP\"]:\n",
    "        print(\"{}---->{}\".format(arr[0][0][-1],row.activity_last_part))\n",
    "\n",
    "df_dupak_all.apply(print_subject,axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f27853b-9e40-4c5e-ab0f-7fca3927f792",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dupak_all.to_csv(\"data/dupak_all.csv\",sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "242641f4-fd92-4ce8-bb89-ee9971ef47fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dupak_all=pd.read_csv(\"data/dupak_all.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "338d9505-4acc-4029-8b92-780417a0cad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VB'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=tagger.tag_sents(['melakukan instalasi'.split()])\n",
    "p[0][0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "d5d911b7-2fdd-44da-a993-927ffbea802d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['pegawai', 'menyiapkan dan memberikan', 'alat video confer', 0.55, 147]]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_word(txt,ref,preserve_empty_words=False):\n",
    "    word=\"\"\n",
    "    try:\n",
    "        rel=txt.split()\n",
    "        rels=[]\n",
    "        for r in rel:\n",
    "            a=r.split(\"_\")\n",
    "            if len(a)==2:\n",
    "                pos=a[0]\n",
    "                idx=a[-1]\n",
    "                label=ref[int(idx)]\n",
    "                if pos in [\"FW\"]:#[\"FW\",\"Z\"]:\n",
    "                    label2=text_preprocessing_en(label)\n",
    "                else:\n",
    "                    label2=text_preprocessing_id(label)\n",
    "                if label2:\n",
    "                    rels.append(label2)\n",
    "                else:\n",
    "                    if preserve_empty_words:\n",
    "                        rels.append(label)\n",
    "        word=\" \".join(rels)\n",
    "    except Exception as x:\n",
    "        print(\"ERROR on text {} why?:{}\".format(txt,str(x)))\n",
    "    return word\n",
    "    \n",
    "    \n",
    "def get_graph_rel(txt):\n",
    "    tagged0=tagger.tag_sents([txt.split()])\n",
    "    if tagged0[0][0][-1]=='VB':\n",
    "        txt='Pegawai '+txt\n",
    "        tagged0=tagger.tag_sents([txt.split()])\n",
    "    ori_pos=[pos[-1]+\"_\"+str(i) for i,pos in enumerate(tagged0[0])]\n",
    "    ori_word=[pos[0] for i,pos in enumerate(tagged0[0])]\n",
    "    pos_sent=\" \".join(ori_pos)\n",
    "    nnps = re.findall(\"[NPFWZ_\\d]{4,6}\\s[NPFWZ_\\d]*\\s*[NPFWZ_\\d]*\\s*[NPFWZ_\\d]*\\s*[NPFWZ_\\d]*\\s*[NPFWZ_\\d]*\\s*[NPFWZ_\\d]*\\s*[NPFWZ_\\d]*\\s*[NPFWZ_\\d]*\\s*[NPFWZ_\\d]*\\s*[NPFWZ_\\d]*\\s*[NPFWZ_\\d]*\\s*[NPFWZ_\\d]*\\s*[NPFWZ_\\d]*\\s*\", pos_sent)\n",
    "    prev=\"\"\n",
    "    edges=[]\n",
    "    for nnp in nnps:\n",
    "        nnp=str(nnp).strip()\n",
    "        if prev:\n",
    "            rel=re.findall(\"(?<=\"+prev+\").*?(?=\"+nnp+\")\",pos_sent)\n",
    "#             print(\"REL:\",rel)\n",
    "            if rel:\n",
    "                rel=rel[0]\n",
    "                try:\n",
    "#                     i=int(rel.split(\"_\")[-1])\n",
    "                    vb=get_word(rel,ori_word,preserve_empty_words=True)#ori_word[i]\n",
    "#                     print(rel+'++++++++'+vb)\n",
    "                    if re.findall(\"\\w+\",vb):\n",
    "                        r=vb#get_word(rel,ori_word)\n",
    "                        nn1=get_word(prev,ori_word)\n",
    "                        nn2=get_word(nnp,ori_word)\n",
    "                        if nn1 and nn2:\n",
    "                            edges.append([nn1,r,nn2,0.55,147])\n",
    "                except Exception as x:\n",
    "                    print(\"ERR on vb:{}:{}\".format(rel,x))\n",
    "                    with open('data/err.txt','a+') as fo:\n",
    "                        fo.write(prev+'---'+rel+'---'+nnp+'\\n')\n",
    "                \n",
    "        prev=nnp\n",
    "\n",
    "    return edges\n",
    "txt='Ahli Muda menyiapkan dan memberikan peralatan video conference (vicon/streaming ), monitoring peralatan (audio,\\nvideo, dan perangkat jaringan), mengatur layout'\n",
    "\n",
    "txt='menyiapkan dan memberikan peralatan video conference'\n",
    "get_graph_rel(txt)\n",
    "# n4j.add_relation(nn1,r,nn2,0.5,147)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee53ace-c180-4581-8739-45157823583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_dupak_to_neo4j(row):\n",
    "    activity=row.activity_last_part\n",
    "    arr=tagger.tag_sents([activity.split()])\n",
    "    if arr[0][0][-1] not in [\"NNP\",\"NN\"]:\n",
    "        activity=\"Prakom \"+row.jenjang+\" \"+activity\n",
    "        \n",
    "    idx=df_dupak_all.index.get_loc(df_dupak_all.index[df_dupak_all['activity_code'] == row.activity_code][0])\n",
    "    idx=int(idx)\n",
    "    ak=row.ak\n",
    "    nodes=get_graph_rel(activity)\n",
    "    for node in nodes:\n",
    "        try:\n",
    "            n4j.add_relation(node[0],node[1],node[2],ak,idx)\n",
    "            pass\n",
    "        except Exception as x:\n",
    "            print(\"ERROR ADD RELATION:{}====>{}\".format(node,x))\n",
    "        \n",
    "#         print(\"{}-{}-{}-{}\".format(node[0],node[1],node[2],ak,idx))\n",
    "tqdm.pandas()\n",
    "df_dupak_all.progress_apply(add_dupak_to_neo4j,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "aa923e84-2e26-4993-aa13-bf25618e0e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ahli muda-alat video confer vicon monitor alat audio video\n",
      "alat video confer vicon monitor alat audio video-perangkat jaring atur\n"
     ]
    }
   ],
   "source": [
    "txt='Ahli Muda menyiapkan dan memberikan peralatan video conference (vicon/streaming ), monitoring peralatan (audio,\\nvideo, dan perangkat jaringan), mengatur layout'\n",
    "res=[]\n",
    "for x in get_graph_rel(txt):\n",
    "    print('{}-{}'.format(x[0],x[2]))\n",
    "    res.append(n4j.query(x[0],x[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e9082a-b90b-42d8-8a05-bbdadcb4365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fastapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "78bc24e1-41cd-4474-8867-b953b9f7a5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============\n",
      "['ahli muda', 'menyiapkan dan memberikan', 'alat video confer vicon monitor alat audio video', 0.55, 147]\n",
      "['alat video confer vicon monitor alat audio video', 'dan', 'perangkat jaring atur', 0.55, 147]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<starlette.responses.JSONResponse at 0x7f32ac55edc0>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastapi.encoders import jsonable_encoder\n",
    "from fastapi.responses import JSONResponse\n",
    "txt='Ahli Muda menyiapkan dan memberikan peralatan video conference (vicon/streaming ), monitoring peralatan (audio,\\nvideo, dan perangkat jaringan), mengatur layout'\n",
    "\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "uri=\"bolt://10.242.184.93:7687\"\n",
    "user='neo4j'\n",
    "password='test'\n",
    "driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "def query_graph(txt):\n",
    "    arr=[]\n",
    "    with driver.session() as session:\n",
    "        for x in get_graph_rel(txt):\n",
    "            print(x)\n",
    "            result = session.run(\"match p=(m)-[r]-(n) where toLower(m.label) contains '\"+str(x[0]).lower()+\"' \\\n",
    "                                 or toLower(n.label) contains '\"+str(x[2]).lower()+\"' return m,r,n\")\n",
    "            tmp={'node1':{},'rel':{},'node2':{}}\n",
    "            for record in result:\n",
    "                tmp['node1']['label']=record['m']['label']\n",
    "                tmp['rel']['label']=record['r']['label']\n",
    "                tmp['rel']['idx']=record['r']['idx']\n",
    "                tmp['rel']['score']=record['r']['score']\n",
    "                tmp['node2']['label']=record['n']['label']\n",
    "#             n1 = [(record['m']['label'],(record['r']['label'],record['r']['idx'],record['r']['score']),record['n']['label']) for record in result]\n",
    "#             print('FOUND RELATIONS({}):{}'.format(len(n1),n1))\n",
    "                arr.append(tmp)\n",
    "#             arr+=n1\n",
    "    result={\"results\":arr}\n",
    "    json_compatible_item_data = jsonable_encoder(result)\n",
    "    return JSONResponse(content=json_compatible_item_data)\n",
    "#     return arr\n",
    "print('=============')\n",
    "a=query_graph(txt)\n",
    "# print('ARR({}):{}'.format(len(a),a))\n",
    "a\n",
    "# session.close()\n",
    "# driver.close()\n",
    "# n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "53eaeb95-2bb0-4fc4-97bb-dacc2489a6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['pegawai', 'melakukan', 'instalasi jaring komputer', 0.55, 147]]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt='melakukan instalasi jaringan komputer'\n",
    "get_graph_rel(txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "85a0d39c-e700-4a4d-b775-c9ee54bb4d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "txt='Ahli Muda menyiapkan dan memberikan peralatan video conference (vicon/streaming ), monitoring peralatan (audio,\\nvideo, dan perangkat jaringan), mengatur layout'\n",
    "txt='menyusun kajian'\n",
    "a=query_graph(txt)\n",
    "b=json.loads(a.body)\n",
    "for i in b['results']:\n",
    "    for k,v in i.items():\n",
    "        print('{}:{}'.format(k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7e11a4-aaf1-4d3c-8685-28613cc1552f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38] *",
   "language": "python",
   "name": "conda-env-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
